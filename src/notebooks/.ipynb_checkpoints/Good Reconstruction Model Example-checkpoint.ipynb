{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d82f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import tensorflow as tf\n",
    "from models.vqvae2_ import *\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os \n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefcead0",
   "metadata": {},
   "source": [
    "# Load Sample Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a7382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rach, sr = librosa.load(\"/Users/llewyn/Documents/recordings/rach.wav\", sr=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9656df5",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1029ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 09:32:22.618833: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-03 09:32:22.618959: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "vqvae_trainer = VQVAETrainer(latent_dim=None, num_embeddings=None)\n",
    "vqvae_trainer.load_weights(\"./example_models/savio_model_1\")\n",
    "vqvae_trainer.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b357d21",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "split audio into stfts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43f51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns magnitude and phase matrices of stft(x)\n",
    "# in shape of (None, 1024, 88)\n",
    "def audio_stfts(x):\n",
    "    x = librosa.util.normalize(x)\n",
    "    stft = librosa.stft(x)\n",
    "    mag = -1 * librosa.amplitude_to_db(np.abs(stft), ref=np.max) / 80.\n",
    "    angle = np.angle(stft)\n",
    "    \n",
    "    chunk_length = 88\n",
    "    if mag.shape[1] % 88 != 0:\n",
    "        multiple = np.ceil(mag.shape[1] / chunk_length)\n",
    "        pad_amount = chunk_length * multiple - mag.shape[1]\n",
    "        mag = np.pad(mag, ((0,0),(0, int(pad_amount))), 'constant', constant_values=(0, 0))\n",
    "\n",
    "        angle = np.pad(angle, ((0,0),(0, int(pad_amount))), 'constant', constant_values=(0, 0))\n",
    "    \n",
    "    chunked_mag, chunked_angle = chunk_stft(mag), chunk_stft(angle)\n",
    "    return chunked_mag[:, :-1, :], chunked_angle[:, :-1, :]\n",
    "\n",
    "def P2R(radii, angles):\n",
    "    return radii * np.exp(1j*angles)\n",
    "\n",
    "# This should invert the results of audio_stfts\n",
    "def reconstruct_audio(chunked_mag, chunked_angle):   \n",
    "    db, angles = concat_stft(chunked_mag), concat_stft(chunked_angle)\n",
    "    stfts = P2R(librosa.db_to_amplitude(db * -80.), angles)\n",
    "    audio = librosa.istft(stfts)\n",
    "    return audio\n",
    "\n",
    "def chunk_stft(stft, chunk_size=88):\n",
    "    new_stft = np.zeros((stft.shape[1] // chunk_size, stft.shape[0], chunk_size))\n",
    "    for i in range(0, stft.shape[1], chunk_size):\n",
    "        chunk_index  = i // chunk_size\n",
    "        new_stft[chunk_index, :, :] = stft[:, i : i + chunk_size]\n",
    "    return new_stft\n",
    "\n",
    "def concat_stft(chunked_stft, chunk_size=88):\n",
    "    stft = np.zeros((chunked_stft.shape[1], chunked_stft.shape[0] * chunked_stft.shape[2]))\n",
    "    \n",
    "    for i in range(0, chunked_stft.shape[0]):\n",
    "        stft[:, i * chunk_size : i*chunk_size + chunk_size] = chunked_stft[i, :, :]\n",
    "    \n",
    "    return stft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595e6d5",
   "metadata": {},
   "source": [
    "# Split and input signal into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7c5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "rach_db, rach_phases = audio_stfts(rach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78fa47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rach_output = vqvae_trainer.vqvae(rach_db)\n",
    "rach_decoded = rach_output.numpy().reshape(rach_db.shape[0], 1024, 88)\n",
    "rach_reconstruction = reconstruct_audio(rach_decoded, rach_phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50a58b",
   "metadata": {},
   "source": [
    "# Original Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e31a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vq_vae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1024, 88, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 256, 22, 128) 427648      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 128, 11, 128) 352768      model[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 11, 64)  8256        model_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "vector_quantizer (VectorQuantiz (None, 128, 11, 64)  32768       conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 256, 22, 64)  352768      vector_quantizer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 22, 192) 0           model_2[0][0]                    \n",
      "                                                                 model[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 22, 64)  12352       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 22, 64)  65600       vector_quantizer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "vector_quantizer_1 (VectorQuant (None, 256, 22, 64)  32768       conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 22, 128) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 vector_quantizer_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 1024, 88, 1)  427521      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,712,449\n",
      "Trainable params: 1,712,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vqvae_trainer.vqvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5acd59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
