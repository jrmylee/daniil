{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "387d0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import pyroomacoustics as pra\n",
    "from nnAudio import Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b2472c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def nn_stft(x):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    x = torch.tensor(x, device=device).float()\n",
    "    spec_layer = Spectrogram.STFT(output_format=\"Magnitude\")\n",
    "    return spec_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb67109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llewyn/miniforge3/lib/python3.9/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "widmung_file = \"/Users/llewyn/Documents/recordings/TrifonovWidmung3.m4a\"\n",
    "widmung, sr = librosa.load(widmung_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee9b2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/Users/llewyn/Documents/data/stft/original\"\n",
    "sample_file = \"MIDI-Unprocessed_08_R3_2008_01-05_ORIG_MID--AUDIO_08_R3_2008_wav--1.wav-0.npy\"\n",
    "\n",
    "stft = np.load(os.path.join(dataset_dir, sample_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b6fa898",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_dir = \"/Users/llewyn/Documents/data/irs/hearst/Position 1/Normalized/Stereo Pairs\"\n",
    "sample_ir = \"HEARST_P1_BLD+BRU.wav\"\n",
    "\n",
    "ir, sr = librosa.load(os.path.join(ir_dir, sample_ir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "066d9b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.0571 seconds\n"
     ]
    }
   ],
   "source": [
    "ir_stft = librosa.stft(ir)\n",
    "ir_stft_ = nn_stft(ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72d97746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d, fftconvolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6779855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9401ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyroomacoustics.directivities import (\n",
    "    DirectivityPattern,\n",
    "    DirectionVector,\n",
    "    CardioidFamily,\n",
    ")\n",
    "import random\n",
    "\n",
    "def get_room_impulse():\n",
    "    # The desired reverberation time and dimensions of the room\n",
    "    rt60 = 3  # seconds\n",
    "    time_range = (1.5, 4)\n",
    "    \n",
    "    length, width, height = random.uniform(35,45),random.uniform(12,25),random.uniform(15,28)\n",
    "    \n",
    "    room_dim = [length, width, height]  # meters\n",
    "\n",
    "    # We invert Sabine's formula to obtain the parameters for the ISM simulator\n",
    "    e_absorption, max_order = pra.inverse_sabine(random.uniform(1.5, 4), room_dim)\n",
    "\n",
    "    # Create the room\n",
    "    room = pra.ShoeBox(\n",
    "        room_dim, fs=22050, materials=pra.Material(e_absorption), max_order=max_order\n",
    "    )\n",
    "    \n",
    "    dir_obj = CardioidFamily(\n",
    "        orientation=DirectionVector(azimuth=90, colatitude=15, degrees=True),\n",
    "        pattern_enum=DirectivityPattern.HYPERCARDIOID,\n",
    "    )\n",
    "    \n",
    "    mic_x, mic_y, mic_z = random.uniform(0, length), random.uniform(0, width), random.uniform(0, height)\n",
    "    \n",
    "    room.add_source(position=[random.uniform(3, 10), random.uniform(3, 10), random.uniform(.9, 1.3)], directivity=dir_obj)\n",
    "    room.add_microphone(loc=[mic_x, mic_y, mic_z], directivity=dir_obj)\n",
    "    \n",
    "    \n",
    "    return room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7f78cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llewyn/miniforge3/lib/python3.9/site-packages/pyroomacoustics/room.py:988: UserWarning: The number of rays used for ray tracing is larger than100000 which may result in slow simulation.  The numberof rays was automatically chosen to provide accurateroom impulse response based on the room volume and thereceiver radius around the microphones.  The number ofrays may be reduced by increasing the size of thereceiver.  This tends to happen especially for largerooms with small receivers.  The receiver is a spherearound the microphone and its radius (in meters) may bespecified by providing the `receiver_radius` keywordargument to the `set_ray_tracing` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "room = get_room_impulse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4159c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "room.compute_rir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "850c56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = room.rir[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31cb4e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125709"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b4a45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "widmung_ = fftconvolve(widmung, ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a0bc98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_tf(x, frame_length=2048, frame_step=512):\n",
    "    pad_amount = 2 * (frame_length - frame_step)\n",
    "    x = tf.pad(x, [[pad_amount // 2, pad_amount // 2]], 'REFLECT')\n",
    "    \n",
    "    f = tf.signal.frame(x, frame_length, frame_step, pad_end=False)\n",
    "    w = tf.signal.hann_window(frame_length, periodic=True)\n",
    "    spectrograms_T = tf.signal.rfft(tf.cast(f, 'float32') * w, fft_length=[frame_length])\n",
    "        \n",
    "    return spectrograms_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "84705598",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_tf_sample = stft_tf(widmung_[10 * sr : 12 * sr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5175709",
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_librosa_sample = librosa.stft(widmung_[10 * sr: 12 * sr], hop_length=512, win_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6adc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
